{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3828ab76",
   "metadata": {},
   "source": [
    "# Load retail food store json data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5860a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       view  temp                   0                                     1  \\\n",
      "0       NaN     1  row-656w.xr9g-izkp  00000000-0000-0000-830A-FB544A42623C   \n",
      "1       NaN     1  row-sip5~swjf.mic4  00000000-0000-0000-1D72-DEFD8206793E   \n",
      "2       NaN     1  row-h2ap-c7pr_kkgm  00000000-0000-0000-87EC-56223CC693F4   \n",
      "3       NaN     1  row-ut8p_acga_u6xi  00000000-0000-0000-2B14-8A8858FE407B   \n",
      "4       NaN     1  row-6ytw~jem2.4fnp  00000000-0000-0000-BDB9-7D5D5C295FDF   \n",
      "...     ...   ...                 ...                                   ...   \n",
      "28515   NaN     1  row-v9cd-gbc6.6u3b  00000000-0000-0000-698E-B98F201A4CB5   \n",
      "28516   NaN     1  row-eizm.b2mt~yi3g  00000000-0000-0000-9CD9-EFBC6C615B05   \n",
      "28517   NaN     1  row-ditr-fpqg-nayr  00000000-0000-0000-E01E-5F5CFE3BBE69   \n",
      "28518   NaN     1  row-i766-7r6j-tuki  00000000-0000-0000-30C0-8088F99C64A1   \n",
      "28519   NaN     1  row-uuzr~e7ps~79md  00000000-0000-0000-BD04-EC6A3A14BF2F   \n",
      "\n",
      "       2           3     4           5     6    7  ...      14             15  \\\n",
      "0      0  1676315083  None  1676315089  None  { }  ...   2712B  E RETMONT AVE   \n",
      "1      0  1676315083  None  1676315089  None  { }  ...     336     E 167TH ST   \n",
      "2      0  1676315083  None  1676315089  None  { }  ...     756      UNION AVE   \n",
      "3      0  1676315083  None  1676315089  None  { }  ...   689NE      1187TH ST   \n",
      "4      0  1676315083  None  1676315089  None  { }  ...    2962  JEROME AVENUE   \n",
      "...   ..         ...   ...         ...   ...  ...  ...     ...            ...   \n",
      "28515  0  1676315083  None  1676315092  None  { }  ...  5754-A         RT 209   \n",
      "28516  0  1676315083  None  1676315092  None  { }  ...     819    MAIN STREET   \n",
      "28517  0  1676315083  None  1676315092  None  { }  ...     241      UNION AVE   \n",
      "28518  0  1676315083  None  1676315092  None  { }  ...      25  WATERFRONT PL   \n",
      "28519  0  1676315083  None  1676315092  None  { }  ...     118        MAIN ST   \n",
      "\n",
      "         16    17            18  19     20    21                          22  \\\n",
      "0      None  None         BRONX  NY  10461     0                        None   \n",
      "1      None  None         BRONX  NY  10456   800  POINT (-73.91264 40.83102)   \n",
      "2      None  None         BRONX  NY  10455     0  POINT (-73.90356 40.81776)   \n",
      "3      None  None         BRONX  NY  10458     0                        None   \n",
      "4      None  None         BRONX  NY  10468  1200  POINT (-73.88961 40.87283)   \n",
      "...     ...   ...           ...  ..    ...   ...                         ...   \n",
      "28515  None  None    KERHONKSON  NY  12446  1600  POINT (-74.25845 41.79006)   \n",
      "28516  None  None  NEW ROCHELLE  NY  10801  1500  POINT (-73.79254 40.90158)   \n",
      "28517  None  None  NEW ROCHELLE  NY  10801  1500  POINT (-73.79541 40.90925)   \n",
      "28518  None  None  PORT CHESTER  NY  10573     0  POINT (-73.66357 40.99826)   \n",
      "28519  None  None      TUCKAHOE  NY  10707     0  POINT (-73.82475 40.94937)   \n",
      "\n",
      "         23  \n",
      "0      None  \n",
      "1       307  \n",
      "2       307  \n",
      "3      None  \n",
      "4       307  \n",
      "...     ...  \n",
      "28515   413  \n",
      "28516   960  \n",
      "28517   960  \n",
      "28518   952  \n",
      "28519   975  \n",
      "\n",
      "[28520 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# load the JSON file as a dictionary\n",
    "with open('Retail_Food_Stores_JSON_File.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# extract the metadata and store it in a dataframe\n",
    "metadata = pd.DataFrame(data['meta'], index=[0])\n",
    "\n",
    "metadata['temp'] = 1\n",
    "# extract the data and store it in a dataframe\n",
    "df = pd.DataFrame(data['data'])\n",
    "\n",
    "df['temp'] = 1\n",
    "# merge the metadata dataframe with the data dataframe\n",
    "result = pd.merge(metadata, df, on='temp')\n",
    "\n",
    "# display the resulting dataframe\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a0d6fb",
   "metadata": {},
   "source": [
    "# Apply appropriate column names to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "197b1ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['view', 'temp', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n"
     ]
    }
   ],
   "source": [
    "column_names = list(result.columns.values)\n",
    "\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8824bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['view', 'temp', 'sid', 'id', 'position', 'created_at', 'created_meta', 'updated_at', 'updated_meta', 'meta_data', 'County', 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n"
     ]
    }
   ],
   "source": [
    "# Rename columns\n",
    "result.rename(columns={\n",
    "    'view': 'view',\n",
    "    'temp': 'temp',\n",
    "    0: 'sid',\n",
    "    1: 'id',\n",
    "    2: 'position',\n",
    "    3: 'created_at',\n",
    "    4: 'created_meta',\n",
    "    5:'updated_at',\n",
    "    6:'updated_meta',\n",
    "    7:'meta_data',\n",
    "    8:'County',\n",
    "}, inplace=True)\n",
    "\n",
    "column_names = list(result.columns.values)\n",
    "\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2846120f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['view', 'temp', 'sid', 'id', 'position', 'created_at', 'created_meta', 'updated_at', 'updated_meta', 'meta_data', 'County', 'License_Number', 'Operation_Type', 'Establishment_Type', 'Entity_Name', 'DBA_Name', 'Street_Number', 'Street_Name', 'Address_Line_2', 'Address_Line_3', 'City', 'State', 'Zip_Code', 'Square_Footage', 'Georeference', 'NYS_Municipal_Boundaries']\n"
     ]
    }
   ],
   "source": [
    "# Rename columns\n",
    "result.rename(columns={\n",
    "    9:'License_Number',\n",
    "    10:'Operation_Type',\n",
    "    11:'Establishment_Type',\n",
    "    12:'Entity_Name',\n",
    "    13:'DBA_Name',\n",
    "    14:'Street_Number',\n",
    "    15:'Street_Name',\n",
    "    16:'Address_Line_2',\n",
    "    17:'Address_Line_3',\n",
    "    18:'City',\n",
    "    19:'State',\n",
    "    20:'Zip_Code',\n",
    "    21:'Square_Footage',\n",
    "    22:'Georeference',\n",
    "    23:'NYS_Municipal_Boundaries'\n",
    "}, inplace=True)\n",
    "\n",
    "column_names = list(result.columns.values)\n",
    "\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21e1315",
   "metadata": {},
   "source": [
    "# Create cassandra session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c4e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "from cassandra.policies import DCAwareRoundRobinPolicy\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "#uth_provider = PlainTextAuthProvider(username='cassandra', password='password')\n",
    "#cluster = Cluster(['127.0.0.1'], load_balancing_policy=DCAwareRoundRobinPolicy(local_dc='US-WEST'), port=9042, auth_provider=auth_provider)\n",
    "auth_provider = PlainTextAuthProvider(username='Test', password='Test@4321')\n",
    "# Connect to the Cassandra cluster\n",
    "cluster = Cluster(['127.0.0.1'], port=9042, auth_provider=auth_provider)\n",
    "session = cluster.connect('dapdb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "b82d45bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete_stmnt = session.prepare('DROP TABLE IF EXISTS dapdb.retail_food_stores')\n",
    "# session.execute(delete_stmnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309eae1e",
   "metadata": {},
   "source": [
    "# Create table of Retail_Food_Stores in Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "816d7727",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_statement = session.prepare('''CREATE TABLE IF NOT EXISTS Retail_Food_Stores (id varchar PRIMARY KEY,County varchar,License_Number varchar,Operation_Type varchar,Establishment_Type varchar,Entity_Name varchar,DBA_Name varchar,Street_Number varchar,Street_Name varchar,Address_Line_2 varchar,Address_Line_3 varchar,City varchar,State varchar,Zip_Code varchar,Square_Footage varchar,Georeference varchar,NYS_Municipal_Boundaries varchar)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "40ac0786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x220901033d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(create_statement)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ab9c45",
   "metadata": {},
   "source": [
    "# Insert values into Retail_Food_Stores table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "553cdc57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "insert_statement = session.prepare('''INSERT INTO retail_food_stores (id,County, License_Number, Operation_Type, Establishment_Type, Entity_Name, DBA_Name, Street_Number, Street_Name, Address_Line_2, Address_Line_3, City, State, Zip_Code, Square_Footage, Georeference, NYS_Municipal_Boundaries) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0b32b254",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LegacyCursorResult' object has no attribute 'iterrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m():\n\u001b[0;32m      2\u001b[0m     session\u001b[38;5;241m.\u001b[39mexecute(insert_statement, [row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m],row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCounty\u001b[39m\u001b[38;5;124m'\u001b[39m],row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLicense_Number\u001b[39m\u001b[38;5;124m'\u001b[39m],row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOperation_Type\u001b[39m\u001b[38;5;124m'\u001b[39m],row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstablishment_Type\u001b[39m\u001b[38;5;124m'\u001b[39m],row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntity_Name\u001b[39m\u001b[38;5;124m'\u001b[39m],row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDBA_Name\u001b[39m\u001b[38;5;124m'\u001b[39m],row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStreet_Number\u001b[39m\u001b[38;5;124m'\u001b[39m],row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStreet_Name\u001b[39m\u001b[38;5;124m'\u001b[39m],row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAddress_Line_2\u001b[39m\u001b[38;5;124m'\u001b[39m],row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAddress_Line_3\u001b[39m\u001b[38;5;124m'\u001b[39m],row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m'\u001b[39m],row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m'\u001b[39m],row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZip_Code\u001b[39m\u001b[38;5;124m'\u001b[39m],row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSquare_Footage\u001b[39m\u001b[38;5;124m'\u001b[39m],row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGeoreference\u001b[39m\u001b[38;5;124m'\u001b[39m],row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNYS_Municipal_Boundaries\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LegacyCursorResult' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "for _, row in result.iterrows():\n",
    "    session.execute(insert_statement, [row['id'],row['County'],row['License_Number'],row['Operation_Type'],row['Establishment_Type'],row['Entity_Name'],row['DBA_Name'],row['Street_Number'],row['Street_Name'],row['Address_Line_2'],row['Address_Line_3'],row['City'],row['State'],row['Zip_Code'],row['Square_Footage'],row['Georeference'],row['NYS_Municipal_Boundaries']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b60ea7",
   "metadata": {},
   "source": [
    "# Load Farmer market json data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db1697a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   view  temp                   0                                     1  2  \\\n",
      "0   NaN     1  row-8bvy~av76~b29y  00000000-0000-0000-28E0-E06AD96EE2A7  0   \n",
      "1   NaN     1  row-s6nz~k9hb_cy4t  00000000-0000-0000-A626-382A53B00DBE  0   \n",
      "2   NaN     1  row-3rrp_2m92-gba2  00000000-0000-0000-3EC6-E88B89C60758  0   \n",
      "3   NaN     1  row-tvpw.ird8-ib3y  00000000-0000-0000-CF90-47907C6B0A6A  0   \n",
      "4   NaN     1  row-aeje_yd3e.62nv  00000000-0000-0000-F62C-A22FDBBC23B5  0   \n",
      "\n",
      "            3     4           5     6    7  ...  \\\n",
      "0  1680644578  None  1680644578  None  { }  ...   \n",
      "1  1680644578  None  1680644578  None  { }  ...   \n",
      "2  1680644578  None  1680644578  None  { }  ...   \n",
      "3  1680644578  None  1680644578  None  { }  ...   \n",
      "4  1680644578  None  1680644578  None  { }  ...   \n",
      "\n",
      "                                            18                   19     20 21  \\\n",
      "0  Mon-Fri 10am-5pm, Sat 10a-4p  Sun 10a-4:30p   June 1-December 23      M  Y   \n",
      "1                                  Sat 9am-1pm    May 6-December 23  P/M/X  Y   \n",
      "2                                 Wed 10am-2pm           Year-round     YR  N   \n",
      "3                                  Sat 9am-1pm  May 14-September 24    P/M  N   \n",
      "4                 Mon-Sat 9am-6pm, Sun 9am-4pm           Year-round     YR  N   \n",
      "\n",
      "  22 23 24        25         26                          27  \n",
      "0  N  N  Y  42.72256  -74.01493  POINT (-74.01493 42.72256)  \n",
      "1  N  N  Y  42.60116     -73.84     POINT (-73.84 42.60116)  \n",
      "2  Y  N  Y  42.65068    -73.758    POINT (-73.758 42.65068)  \n",
      "3  N  N  Y  42.71016  -73.78029  POINT (-73.78029 42.71016)  \n",
      "4  N  N  Y  42.71055  -73.92593  POINT (-73.92593 42.71055)  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# load the JSON file as a dictionary\n",
    "with open('C:\\\\Users\\\\AISHWARYA UBALE\\\\Downloads\\\\Farmers_Dataset_JSON_Format.json', 'r', encoding='utf-8') as file:\n",
    "    farmer_data = json.load(file)\n",
    "\n",
    "# extract the metadata and store it in a dataframe\n",
    "farmer_metadata = pd.DataFrame(farmer_data['meta'], index=[0])\n",
    "\n",
    "farmer_metadata['temp'] = 1\n",
    "# extract the data and store it in a dataframe\n",
    "df_farmer = pd.DataFrame(farmer_data['data'])\n",
    "\n",
    "df_farmer['temp'] = 1\n",
    "# merge the metadata dataframe with the data dataframe\n",
    "farmer_result = pd.merge(farmer_metadata, df_farmer, on='temp')\n",
    "\n",
    "# display the resulting dataframe\n",
    "print(farmer_result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb76159b",
   "metadata": {},
   "source": [
    "# Apply appropriate column names to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8ef258e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['view', 'temp', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n"
     ]
    }
   ],
   "source": [
    "farmer_result_column_names = list(farmer_result.columns.values)\n",
    "\n",
    "print(farmer_result_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "81054257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['view', 'temp', 'sid', 'id', 'position', 'created_at', 'created_meta', 'updated_at', 'updated_meta', 'meta_data', 'County', 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n"
     ]
    }
   ],
   "source": [
    "# Rename columns\n",
    "farmer_result.rename(columns={\n",
    "    'view': 'view',\n",
    "    'temp': 'temp',\n",
    "    0: 'sid',\n",
    "    1: 'id',\n",
    "    2: 'position',\n",
    "    3: 'created_at',\n",
    "    4: 'created_meta',\n",
    "    5:'updated_at',\n",
    "    6:'updated_meta',\n",
    "    7:'meta_data',\n",
    "    8:'County',\n",
    "}, inplace=True)\n",
    "\n",
    "farmer_result_column_names = list(farmer_result.columns.values)\n",
    "\n",
    "print(farmer_result_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c727ebab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['view', 'temp', 'sid', 'id', 'position', 'created_at', 'created_meta', 'updated_at', 'updated_meta', 'meta_data', 'County', 'Market_Name', 'Market_Location', 'Address_Line_1', 'City', 'State', 'Zip', 'Contact', 'Phone', 'Market_Link', 'Operation_Hours', 'Operation_Season', 'Operating_Months', 'FMNP', 'SNAP', 'FCC_Issued', 'FCC_Accepted', 'Latitude', 'Longitude', 'Georeference_1']\n"
     ]
    }
   ],
   "source": [
    "# Rename columns\n",
    "farmer_result.rename(columns={\n",
    "    9:'Market_Name',\n",
    "    10:'Market_Location',\n",
    "    11:'Address_Line_1',\n",
    "    12:'City',\n",
    "    13:'State',\n",
    "    14:'Zip',\n",
    "    15:'Contact',\n",
    "    16:'Phone',\n",
    "    17:'Market_Link',\n",
    "    18:'Operation_Hours',\n",
    "    19:'Operation_Season',\n",
    "    20:'Operating_Months',\n",
    "    21:'FMNP',\n",
    "    22:'SNAP',\n",
    "    23:'FCC_Issued',\n",
    "    24:'FCC_Accepted',\n",
    "    25:'Latitude',\n",
    "    26:'Longitude',\n",
    "    27:'Georeference_1'\n",
    "}, inplace=True)\n",
    "\n",
    "farmer_result_column_names = list(farmer_result.columns.values)\n",
    "\n",
    "print(farmer_result_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8db0b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete_stmnt = session.prepare('DROP TABLE IF EXISTS dapdb.Farmer_Market_NYC')\n",
    "# session.execute(delete_stmnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af97b92",
   "metadata": {},
   "source": [
    "# Create table of Farmer_Market in Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "799bcfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_statement = session.prepare('''CREATE TABLE IF NOT EXISTS Farmer_Market_NYC (id varchar PRIMARY KEY,County varchar,Market_Name varchar,Market_Location varchar,Address_Line_1 varchar,City varchar,State varchar,Zip varchar,Contact varchar,Phone varchar,Operation_Hours varchar,Operation_Season varchar,Operating_Months varchar,FMNP varchar,SNAP varchar,FCC_Issued varchar, FCC_Accepted varchar,Latitude varchar,Longitude varchar,Georeference_1 varchar)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b047ba8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x22090101990>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(create_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c144450",
   "metadata": {},
   "source": [
    "# Insert values into Farmer_Market table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "51a5833f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "view                  0\n",
       "temp                405\n",
       "sid                 405\n",
       "id                  405\n",
       "position            405\n",
       "created_at          405\n",
       "created_meta          0\n",
       "updated_at          405\n",
       "updated_meta          0\n",
       "meta_data           405\n",
       "County              405\n",
       "Market_Name         405\n",
       "Market_Location     405\n",
       "Address_Line_1      405\n",
       "City                405\n",
       "State               405\n",
       "Zip                 405\n",
       "Contact             405\n",
       "Phone               403\n",
       "Market_Link         308\n",
       "Operation_Hours     405\n",
       "Operation_Season    405\n",
       "Operating_Months    405\n",
       "FMNP                405\n",
       "SNAP                405\n",
       "FCC_Issued          405\n",
       "FCC_Accepted        405\n",
       "Latitude            405\n",
       "Longitude           405\n",
       "Georeference_1      405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_statement = session.prepare('''INSERT INTO Farmer_Market_NYC (id,County, Market_Name, Market_Location, Address_Line_1, City, State, Zip, Contact, Phone, Operation_Hours, Operation_Season, Operating_Months, FMNP, SNAP, FCC_Issued, FCC_Accepted, Latitude, Longitude, Georeference_1) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)''')\n",
    "farmer_result.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e52bb94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in farmer_result.iterrows():\n",
    "    session.execute(insert_statement, [row['id'],row['County'],row['Market_Name'],row['Market_Location'],row['Address_Line_1'],row['City'],row['State'],row['Zip'],row['Contact'],row['Phone'],row['Operation_Hours'],row['Operation_Season'],row['Operating_Months'],row['FMNP'],row['SNAP'],row['FCC_Issued'],row['FCC_Accepted'],row['Latitude'],row['Longitude'],row['Georeference_1']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8488aac3",
   "metadata": {},
   "source": [
    "## ETL Process: Load data from cassandra database & transform data into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3e13560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import luigi\n",
    "from luigi import build\n",
    "import pandas as pd\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.policies import DCAwareRoundRobinPolicy\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.policies import DCAwareRoundRobinPolicy\n",
    "from cassandra.auth import PlainTextAuthProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f1da02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extract_Retail_CassandraTask(luigi.Task):\n",
    "    def output(self):\n",
    "        return luigi.LocalTarget(\"C:\\\\Users\\\\AISHWARYA UBALE\\\\Documents\\\\NCI_Projects\\\\DAP_Retail_Food_Shop\\\\extracted_cassandra_retail_food_shop.csv\")\n",
    "    \n",
    "    def run(self):\n",
    "        # Execute a CQL query to retrieve the contents of a table\n",
    "        retail_query = \"SELECT * FROM retail_food_stores\"\n",
    "        retail_rows = session.execute(retail_query)\n",
    "        # Convert the results to a Pandas DataFrame\n",
    "        extracted_retail_df = pd.DataFrame(retail_rows)\n",
    "        \n",
    "    #Save retail_food_shop data to CSV file\n",
    "        with self.output().open('w') as f:\n",
    "            # Write the header row\n",
    "            header = ','.join(extracted_retail_df.columns) + '\\n'\n",
    "            f.write(header)\n",
    "            for _, row in extracted_retail_df.iterrows():\n",
    "                # Replace any commas or pound signs in the data with spaces\n",
    "                row = [str(val).replace(',', ' ').replace('#', ' ') for val in row]\n",
    "                # Join the row values with commas and write them to the CSV\n",
    "                f.write(','.join(row) + '\\n')        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0990e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess_Retail_CassandraTask(luigi.Task):\n",
    "    \n",
    "    def requires(self):\n",
    "        return Extract_Retail_CassandraTask()\n",
    "    \n",
    "    def output(self):\n",
    "        return luigi.LocalTarget(\"C:\\\\Users\\\\AISHWARYA UBALE\\\\Documents\\\\NCI_Projects\\\\DAP_Retail_Food_Shop\\\\cassandra_retail_food_shop.csv\")\n",
    "    \n",
    "    def camel_case(self,s):\n",
    "        words = s.split('_')\n",
    "        camel_case_words = [words[0]] + [word.capitalize() for word in words[1:]]\n",
    "        # Join the words back together\n",
    "        camel_case_string = ''.join(camel_case_words)\n",
    "        return camel_case_string\n",
    "    \n",
    "    def cleaningData(self,to_be_cleaned_retail_df):\n",
    "        #Removing unwanted columns\n",
    "        to_be_cleaned_retail_df = to_be_cleaned_retail_df.drop(['address_line_2', 'address_line_3'], axis=1)\n",
    "        # Remove blanks and None values\n",
    "        cleaned_retail_df = to_be_cleaned_retail_df.dropna()\n",
    "        # drop all rows with NaN values\n",
    "        # Apply camel-case to column names\n",
    "        cleaned_retail_df.columns = [self.camel_case(col) for col in cleaned_retail_df.columns]\n",
    "\n",
    "        return cleaned_retail_df\n",
    "    \n",
    "    def run(self):\n",
    "        #to_be_cleaned_retail_df = retail_df\n",
    "        extracted_retail_df = pd.read_csv('C:\\\\Users\\\\AISHWARYA UBALE\\\\Documents\\\\NCI_Projects\\\\DAP_Retail_Food_Shop\\\\extracted_cassandra_retail_food_shop.csv')\n",
    "        to_be_cleaned_retail_df = extracted_retail_df\n",
    "        cleaned_retail_df = self.cleaningData(to_be_cleaned_retail_df)\n",
    "        #Creating location dataframe\n",
    "        final_retail_food_store_dataframe = cleaned_retail_df[['id','licenseNumber','operationType','establishmentType','entityName','squareFootage','dbaName','streetNumber','nysMunicipalBoundaries']]\n",
    "        #Creating Retail_food_store dataframe\n",
    "        location_dataframe = cleaned_retail_df[['county','city','state','zipCode','georeference','streetName','streetNumber']]\n",
    "        \n",
    "        \n",
    "        #Save retail_food_shop data to CSV file\n",
    "        with self.output().open('w') as f:\n",
    "            # Write the header row\n",
    "            header = ','.join(final_retail_food_store_dataframe.columns) + '\\n'\n",
    "            f.write(header)\n",
    "            for _, row in final_retail_food_store_dataframe.iterrows():\n",
    "                # Replace any commas or pound signs in the data with spaces\n",
    "                row = [str(val).replace(',', ' ').replace('#', ' ') for val in row]\n",
    "                # Join the row values with commas and write them to the CSV\n",
    "                f.write(','.join(row) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b77f6a",
   "metadata": {},
   "source": [
    "# Connecting with postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ed97d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas.io.sql as sqlio\n",
    "import seaborn as sns \n",
    "from sqlalchemy import create_engine, event, text, exc \n",
    "from sqlalchemy.engine.url import URL\n",
    "import luigi\n",
    "from luigi import build\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import csv\n",
    "\n",
    "class CreateDatabaseTask(luigi.Task):\n",
    "\n",
    "    def run(self):\n",
    "        connection_string = \"postgresql://postgres:testpass@127.0.0.1:5432/postgres\"\n",
    "        try : \n",
    "            engine = create_engine(connection_string)\n",
    "            with engine.connect() as connection: \n",
    "                connection.execution_options(isolation_level=\"AUTOCOMMIT\") \n",
    "                #CREATE TABLE IF NOT EXISTS table_name\n",
    "                result = connection.execute(f\"SELECT 1 FROM pg_catalog.pg_database WHERE datname = 'dapdb_postgres';\")\n",
    "                exists = result.fetchone()\n",
    "                if not exists:\n",
    "                    connection.execute(f\"CREATE DATABASE dapdb_postgres;\")\n",
    "                    print(\"Note: Database Created!\")\n",
    "                else:\n",
    "                    print(\"Note: Database Already exists!!\")\n",
    "        except exc.SQLAlchemyError as dbError:\n",
    "            print (\"PostgreSQL Error\", dbError) \n",
    "        finally : \n",
    "            if engine in locals():\n",
    "                engine.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0d1ed62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Checking if CreateDatabaseTask() is complete\n",
      "C:\\Users\\AISHWARYA UBALE\\anaconda3\\lib\\site-packages\\luigi\\worker.py:419: UserWarning: Task CreateDatabaseTask() without outputs has no custom complete() method\n",
      "  is_complete = task.complete()\n",
      "INFO: Informed scheduler that task   CreateDatabaseTask__99914b932b   has status   PENDING\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 1\n",
      "INFO: [pid 14640] Worker Worker(salt=799898582, workers=1, host=LAPTOP-BQ79RF01, username=AISHWARYA UBALE, pid=14640) running   CreateDatabaseTask()\n",
      "INFO: [pid 14640] Worker Worker(salt=799898582, workers=1, host=LAPTOP-BQ79RF01, username=AISHWARYA UBALE, pid=14640) done      CreateDatabaseTask()\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   CreateDatabaseTask__99914b932b   has status   DONE\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Done\n",
      "DEBUG: There are no more tasks to run at this time\n",
      "INFO: Worker Worker(salt=799898582, workers=1, host=LAPTOP-BQ79RF01, username=AISHWARYA UBALE, pid=14640) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 1 tasks of which:\n",
      "* 1 ran successfully:\n",
      "    - 1 CreateDatabaseTask()\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Database Already exists!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = CreateDatabaseTask()\n",
    "luigi.build([task], local_scheduler=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0209bf52",
   "metadata": {},
   "source": [
    "## Luigi task for inserting extracted data of retail_food_stores into postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6985201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import luigi\n",
    "from luigi import build\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import csv\n",
    "\n",
    "class Load_to_Postgres_Retail(luigi.Task):\n",
    "    def requires(self):\n",
    "        return Preprocess_Retail_CassandraTask()\n",
    "    \n",
    "    def output(self):\n",
    "        #Returns the output target for this task.\n",
    "        return luigi.LocalTarget(\"C:\\\\Users\\\\AISHWARYA UBALE\\\\Documents\\\\NCI_Projects\\\\DAP_Retail_Food_Shop\\\\cassandra_retail_food_shop1.csv\")\n",
    "    \n",
    "    def run(self):\n",
    "        \n",
    "        #Loads the CSV data into PostgreSQL.\n",
    "        \n",
    "        # Connect to the PostgreSQL database\n",
    "        conn = psycopg2.connect(\"postgresql://postgres:testpass@127.0.0.1:5432/dapdb_postgres\")\n",
    "        \n",
    "        # Create a cursor\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        # Create the table\n",
    "        cur.execute(f\"\"\"CREATE TABLE IF NOT EXISTS retail_food_stores(id varchar(100) NOT NULL,\n",
    "                        licenseNumber int NOT NULL,operationType varchar(50) NOT NULL,establishmentType varchar(100) NOT NULL,\n",
    "                        entityName varchar(100) NOT NULL,squareFootage int NOT NULL, \n",
    "                        dbaName varchar(100) NOT NULL, streetNumber varchar(100) NOT NULL,nysMunicipalBoundaries int NOT NULL); \"\"\")\n",
    "\n",
    "        cur.execute(f\"SELECT 1 FROM retail_food_stores LIMIT 1\")\n",
    "        rows = cur.fetchall()\n",
    "        print(\"Length of the postgres created table: \",len(rows))\n",
    "        if len(rows) == 0:\n",
    "            #Insert the CSV file data in the postgres database\n",
    "            with open(\"C:\\\\Users\\\\AISHWARYA UBALE\\\\Documents\\\\NCI_Projects\\\\DAP_Retail_Food_Shop\\\\cassandra_retail_food_shop.csv\", 'r') as f:\n",
    "                next(f) # Skip the header row.\n",
    "                cur.copy_from(f, 'retail_food_stores', sep=',')\n",
    "                cur.execute(f\"ALTER TABLE retail_food_stores ADD COLUMN indexId SERIAL PRIMARY KEY NOT NULL;\")\n",
    "        \n",
    "        \n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "        \n",
    "        # Close the cursor and the connection\n",
    "        cur.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ee605e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import luigi\n",
    "\n",
    "class AllTasks(luigi.WrapperTask):\n",
    "    def requires(self):\n",
    "        yield Load_to_Postgres_Retail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9a51a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Checking if Load_to_Postgres_Retail() is complete\n",
      "DEBUG: Checking if Preprocess_Retail_CassandraTask() is complete\n",
      "INFO: Informed scheduler that task   Load_to_Postgres_Retail__99914b932b   has status   PENDING\n",
      "DEBUG: Checking if Extract_Retail_CassandraTask() is complete\n",
      "INFO: Informed scheduler that task   Preprocess_Retail_CassandraTask__99914b932b   has status   PENDING\n",
      "INFO: Informed scheduler that task   Extract_Retail_CassandraTask__99914b932b   has status   PENDING\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 3\n",
      "INFO: [pid 14640] Worker Worker(salt=7631116528, workers=1, host=LAPTOP-BQ79RF01, username=AISHWARYA UBALE, pid=14640) running   Extract_Retail_CassandraTask()\n",
      "INFO: [pid 14640] Worker Worker(salt=7631116528, workers=1, host=LAPTOP-BQ79RF01, username=AISHWARYA UBALE, pid=14640) done      Extract_Retail_CassandraTask()\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   Extract_Retail_CassandraTask__99914b932b   has status   DONE\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 2\n",
      "INFO: [pid 14640] Worker Worker(salt=7631116528, workers=1, host=LAPTOP-BQ79RF01, username=AISHWARYA UBALE, pid=14640) running   Preprocess_Retail_CassandraTask()\n",
      "INFO: [pid 14640] Worker Worker(salt=7631116528, workers=1, host=LAPTOP-BQ79RF01, username=AISHWARYA UBALE, pid=14640) done      Preprocess_Retail_CassandraTask()\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   Preprocess_Retail_CassandraTask__99914b932b   has status   DONE\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 1\n",
      "INFO: [pid 14640] Worker Worker(salt=7631116528, workers=1, host=LAPTOP-BQ79RF01, username=AISHWARYA UBALE, pid=14640) running   Load_to_Postgres_Retail()\n",
      "INFO: [pid 14640] Worker Worker(salt=7631116528, workers=1, host=LAPTOP-BQ79RF01, username=AISHWARYA UBALE, pid=14640) done      Load_to_Postgres_Retail()\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   Load_to_Postgres_Retail__99914b932b   has status   DONE\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Done\n",
      "DEBUG: There are no more tasks to run at this time\n",
      "INFO: Worker Worker(salt=7631116528, workers=1, host=LAPTOP-BQ79RF01, username=AISHWARYA UBALE, pid=14640) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 3 tasks of which:\n",
      "* 3 ran successfully:\n",
      "    - 1 Extract_Retail_CassandraTask()\n",
      "    - 1 Load_to_Postgres_Retail()\n",
      "    - 1 Preprocess_Retail_CassandraTask()\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the postgres created table:  1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    luigi.build([Load_to_Postgres_Retail()], scheduler_host='localhost', scheduler_port=8082)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69866741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
